[Global]
Ingest-Secret = "IngestSecrets"
Connection-Timeout = 0
Insecure-Skip-TLS-Verify=false
#Cleartext-Backend-Target=127.0.0.1:4023 #example of adding a cleartext connection
#Cleartext-Backend-Target=127.1.0.1:4023 #example of adding another cleartext connection
#Encrypted-Backend-Target=127.1.1.1:4024 #example of adding an encrypted connection
Pipe-Backend-Target=/opt/gravwell/comms/pipe #a named pipe connection, this should be used when ingester is on the same machine as a backend
#Ingest-Cache-Path=/opt/gravwell/cache/s3.cache #adding an ingest cache for local storage when uplinks fail
#Max-Ingest-Cache=1024 #Number of MB to store, localcache will only store 1GB before stopping.  This is a safety net
Log-Level=INFO
Log-File=/opt/gravwell/log/sq3.log
State-Store-Location=/opt/gravwell/etc/s3.state

# A Bucket scans and pulls S3 objects from a given S3 bucket.
# The region, bucket URL, Authorization ID, and Secret are all required
# The authorization tokens only require Read only access, no writes will be performed
# https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys
# for information about obtaining an ID/Secret for your user.
[Bucket "default"]
	Region="us-east-2"
	Bucket-ARN="my_super_secret_bucket"
	Tag-Name="s3"
	ID="ID..."
	Secret="..."
	#Assume-Local-Timezone=false #Default for assume localtime is false
	#Source-Override="DEAD::BEEF" #override the source for just this Queue 
	#Max-Line-Size=67108864 #enable very large lines to deal with clouttrail objects
	#File-Filters=*.json.gz #example matching only top level objects that end in .json.gz
	#File-Filters=*.json #example of adding another filter
	#File-Filters=**/*.json.gz #example of adding a filter that will match all subdirectories
